echo 'TODO[ldery] - check that the data set and output locations are correct on cloud before running'
mkdir output_models
# IMDB CROSSED
CUDA_VISIBLE_DEVICES=0 python -u -m scripts.run_language_modeling --train_data_file datasets/imdb_data/all_training_joined.txt --line_by_line  --model_type roberta-base --tokenizer_name roberta-base --mlm --per_gpu_train_batch_size 8 --gradient_accumulation_steps 32 --model_name_or_path roberta-base --eval_data_file datasets/imdb_data/dev.txt  --do_eval  --evaluate_during_training  --do_train --num_train_epochs 100 --learning_rate 0.0001 --logging_steps 2000 --base_task_dataset_file datasets/imdb_data/train.jsonl --dev_task_file datasets/imdb_data/dev.jsonl --test_task_file datasets/imdb_data/test.jsonl --num_samples_for_basis 32  --num_basis 5 --overwrite_output_dir --pca_every 1 --n_subspace_layers -12 --eta_set "(1.0, 1.0, 0.0)" --classifier_dropout 0.2 --classf_lr 1e-4 --lm_mt_task_weight 0.0025 --classf_pretr_patience 20 --output_dir output_models/roberta-imdb-tapt_1.1.0_vwgt_0.0025 &> output_models/roberta-imdb-tapt_1.1.0_vwgt_0.0025.txt &
CUDA_VISIBLE_DEVICES=1 python -u -m scripts.run_language_modeling --train_data_file datasets/imdb_data/all_training_joined.txt --line_by_line  --model_type roberta-base --tokenizer_name roberta-base --mlm --per_gpu_train_batch_size 8 --gradient_accumulation_steps 32 --model_name_or_path roberta-base --eval_data_file datasets/imdb_data/dev.txt  --do_eval  --evaluate_during_training  --do_train --num_train_epochs 100 --learning_rate 0.0001 --logging_steps 2000 --base_task_dataset_file datasets/imdb_data/train.jsonl --dev_task_file datasets/imdb_data/dev.jsonl --test_task_file datasets/imdb_data/test.jsonl --num_samples_for_basis 32  --num_basis 5 --overwrite_output_dir --pca_every 1 --n_subspace_layers -12 --eta_set "(1.0, 1.0, -1.0)" --classifier_dropout 0.2 --classf_lr 1e-4 --lm_mt_task_weight 0.0025 --classf_pretr_patience 20 --output_dir output_models/roberta-imdb-tapt_1.1.-1_vwgt_0.0025 &> output_models/roberta-imdb-tapt_1.1.-1_vwgt_0.0025.txt &
